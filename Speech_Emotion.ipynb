{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fe423a8a12c49dcacb0167816426c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d093a828f4614b34ad79a23dbcf7b511",
              "IPY_MODEL_ce18b8ab685b48e78f5de1a6404cba60",
              "IPY_MODEL_f623842d15654d8a8caf929711b21a82"
            ],
            "layout": "IPY_MODEL_f131a1fdbdf34f61ad9e4d57ec626837"
          }
        },
        "d093a828f4614b34ad79a23dbcf7b511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1be03ae8e44e558f06efae0a6be784",
            "placeholder": "​",
            "style": "IPY_MODEL_37ee6ecf4ad94c9bbbf9b73df54736b6",
            "value": ""
          }
        },
        "ce18b8ab685b48e78f5de1a6404cba60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778f8aa17d7c4e4eb1ca3b69dbefb6e0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b7a868118004b718910176fe0aab430",
            "value": 0
          }
        },
        "f623842d15654d8a8caf929711b21a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f931f7526b425087db12b40d5bd81f",
            "placeholder": "​",
            "style": "IPY_MODEL_c86569759e1d4c46b5d1dc5d4dd2a548",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "f131a1fdbdf34f61ad9e4d57ec626837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1be03ae8e44e558f06efae0a6be784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ee6ecf4ad94c9bbbf9b73df54736b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778f8aa17d7c4e4eb1ca3b69dbefb6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9b7a868118004b718910176fe0aab430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66f931f7526b425087db12b40d5bd81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86569759e1d4c46b5d1dc5d4dd2a548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b5b677c7d8747dd8cefc7d4d0710277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1131c718470143bd88e01e3549edba29",
              "IPY_MODEL_fe18b12e09354aec892449651c15bd43",
              "IPY_MODEL_905ca4c55d16455aa7240a315f099af0"
            ],
            "layout": "IPY_MODEL_32307ff7442c4ef796d89536b1cfe482"
          }
        },
        "1131c718470143bd88e01e3549edba29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ee709b049c45e39bd07b02ea94a3e3",
            "placeholder": "​",
            "style": "IPY_MODEL_37fd0c0a6b924a20aeb5cf9e802903c7",
            "value": "Downloading: 100%"
          }
        },
        "fe18b12e09354aec892449651c15bd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ca68784847446d3893587296ede223f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3841d8f00445442c87bb35233391f75f",
            "value": 231508
          }
        },
        "905ca4c55d16455aa7240a315f099af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f584d511b0e14e28a2f225967212b5ef",
            "placeholder": "​",
            "style": "IPY_MODEL_40bc3f73fd7a49aa8d50673c807c87c9",
            "value": " 232k/232k [00:00&lt;00:00, 362kB/s]"
          }
        },
        "32307ff7442c4ef796d89536b1cfe482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ee709b049c45e39bd07b02ea94a3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37fd0c0a6b924a20aeb5cf9e802903c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ca68784847446d3893587296ede223f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3841d8f00445442c87bb35233391f75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f584d511b0e14e28a2f225967212b5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40bc3f73fd7a49aa8d50673c807c87c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1036799f04a14c28ac243552ef8a4870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffff46519b514cc0bdeb6339cd02cc00",
              "IPY_MODEL_46eccc3d5dc84be3a277bfdcf57a5057",
              "IPY_MODEL_2a8c31197f0247d28432406aec07cbeb"
            ],
            "layout": "IPY_MODEL_aa5ad979ceb247d692e5b9facd161963"
          }
        },
        "ffff46519b514cc0bdeb6339cd02cc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70172610177f49689f2583f16a589640",
            "placeholder": "​",
            "style": "IPY_MODEL_0f34717e2c1748c193e67278f6480def",
            "value": "Downloading: 100%"
          }
        },
        "46eccc3d5dc84be3a277bfdcf57a5057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_097802d968944fdf97ff3027780f505d",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d122733e95034865a4cf0898de0b6e89",
            "value": 28
          }
        },
        "2a8c31197f0247d28432406aec07cbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5978e323bb341f18aa0f7dba7036923",
            "placeholder": "​",
            "style": "IPY_MODEL_f5ada72a7078411ba690f68c9b65ab71",
            "value": " 28.0/28.0 [00:00&lt;00:00, 964B/s]"
          }
        },
        "aa5ad979ceb247d692e5b9facd161963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70172610177f49689f2583f16a589640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f34717e2c1748c193e67278f6480def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "097802d968944fdf97ff3027780f505d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d122733e95034865a4cf0898de0b6e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5978e323bb341f18aa0f7dba7036923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ada72a7078411ba690f68c9b65ab71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6edfe08ce9c4d6498ec6cca84eb88eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37db39c78561409aa01d1cd175843879",
              "IPY_MODEL_c7a64ef8b34b473b84b7e9e97529b7b7",
              "IPY_MODEL_f06d7ed43bd1460dacb63cf862ae97fa"
            ],
            "layout": "IPY_MODEL_f7dafeb84a0e4b12a4dbbdaa7b061455"
          }
        },
        "37db39c78561409aa01d1cd175843879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16fcebc15f3a4cc6b3cc6d3a46cc6be2",
            "placeholder": "​",
            "style": "IPY_MODEL_0b83305c30fc461e97145690905d764b",
            "value": "Downloading: 100%"
          }
        },
        "c7a64ef8b34b473b84b7e9e97529b7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_732a60eebace40c090591308c8a19087",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fcc6963bffe474a855ea34068430cf7",
            "value": 570
          }
        },
        "f06d7ed43bd1460dacb63cf862ae97fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df917701cee47d68a0de72a4138a96b",
            "placeholder": "​",
            "style": "IPY_MODEL_3ade6fe43e7f4920bc9ea5303f89511b",
            "value": " 570/570 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "f7dafeb84a0e4b12a4dbbdaa7b061455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16fcebc15f3a4cc6b3cc6d3a46cc6be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b83305c30fc461e97145690905d764b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "732a60eebace40c090591308c8a19087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fcc6963bffe474a855ea34068430cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df917701cee47d68a0de72a4138a96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ade6fe43e7f4920bc9ea5303f89511b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Transcription of Audio"
      ],
      "metadata": {
        "id": "E2KpnJVJpE49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8bLyCpB9zAb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename, chunk_size=5242880):\n",
        "    with open(filename, 'rb') as _file:\n",
        "        while True:\n",
        "            data = _file.read(chunk_size)\n",
        "            if not data:\n",
        "                break\n",
        "            yield data"
      ],
      "metadata": {
        "id": "gdp51c5j91tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_url(token,filepath):\n",
        "  '''\n",
        "    Parameter:\n",
        "      token: The API key\n",
        "      data : The File Object to upload\n",
        "    Return Value:\n",
        "      url  : Url to uploaded file\n",
        "  '''\n",
        "  headers = {'authorization': token}\n",
        "  response = requests.post('https://api.assemblyai.com/v2/upload',\n",
        "                         headers=headers,\n",
        "                         data=read_file(filepath))\n",
        "  url = response.json()[\"upload_url\"]\n",
        "  print(\"Uploaded File and got temporary URL to file\")\n",
        "  return url"
      ],
      "metadata": {
        "id": "FlALP9rZ92YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transcribe_id(token,url):\n",
        "  '''\n",
        "    Parameter:\n",
        "      token: The API key\n",
        "      url  : Url to uploaded file\n",
        "    Return Value:\n",
        "      id   : The transcribe id of the file\n",
        "  '''\n",
        "  endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
        "  json = {\n",
        "    \"audio_url\": url,\"speaker_labels\": True,\"auto_highlights\": True\n",
        "  }\n",
        "  headers = {\n",
        "    \"authorization\": token,\n",
        "    \"content-type\": \"application/json\"\n",
        "  }\n",
        "  response = requests.post(endpoint, json=json, headers=headers)\n",
        "  id = response.json()['id']\n",
        "  print(\"Made request and file is currently queued\")\n",
        "  return id"
      ],
      "metadata": {
        "id": "NrKpuygf94vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(token,filepath):\n",
        "  '''\n",
        "    Parameter: \n",
        "      filepath: The File Object to transcribe\n",
        "    Return Value:\n",
        "      token  : The API key\n",
        "      transcribe_id: The ID of the file which is being transcribed\n",
        "  '''\n",
        "  \n",
        "  # token = \"398a8ab00a764f0092e93ff6a480a68f\"\n",
        "  file_url = get_url(token,filepath)\n",
        "  transcribe_id = get_transcribe_id(token,file_url)\n",
        "  return transcribe_id"
      ],
      "metadata": {
        "id": "_QPoyHIL96_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(token,transcribe_id):\n",
        "  '''\n",
        "    Parameter: \n",
        "      token: The API key\n",
        "      transcribe_id: The ID of the file which is being \n",
        "    Return Value:\n",
        "      result : The response object\n",
        "  '''  \n",
        "  endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcribe_id}\"\n",
        "  headers = {\n",
        "    \"authorization\": token\n",
        "  }\n",
        "  result = requests.get(endpoint, headers=headers).json()\n",
        "  return result"
      ],
      "metadata": {
        "id": "0bKcu4dp99Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_data_extraction(result,fname):\n",
        "\n",
        "    audindex = pd.json_normalize(result['words'])\n",
        "    audindex['fname'] = fname\n",
        "\n",
        "    speakers = list(audindex.speaker)  # Change df to your dataframe name\n",
        "    previous_speaker = 'A'\n",
        "    l = len(speakers)\n",
        "    i = 1\n",
        "    speaker_seq_list = list()\n",
        "    for index, new_speaker in enumerate(speakers):\n",
        "        if index > 0:\n",
        "            previous_speaker = speakers[index - 1]\n",
        "        if new_speaker != previous_speaker:\n",
        "            i += 1\n",
        "        speaker_seq_list.append(i)\n",
        "        # print(str(previous_speaker)+\"  \"+str(new_speaker)+\"  \"+str(i))\n",
        "    audindex['seq'] = speaker_seq_list\n",
        "    df = pd.DataFrame(audindex.groupby(['fname', 'speaker', 'seq']).agg(utter=('text', ' '.join), stime=('start', 'min'),etime=('end', 'max')))\n",
        "    df.reset_index(inplace=True)\n",
        "    df.sort_values(by=['stime'], inplace=True)\n",
        "\n",
        "    df['stime'] = df.stime // 1000\n",
        "    df['etime'] = df.etime // 1000\n",
        "    df['seq'] = df.seq - 1\n",
        "    df.rename(columns = {'speaker':'spcode'},inplace=True)\n",
        "    # df.to_csv('tx_speaker_db.csv', mode='a', header=False, index=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "VRleUnbU-Ba4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_csv(audio_filepath):\n",
        "  fname = os.path.splitext(os.path.basename(audio_filepath))[0]\n",
        "  token =  \"a2b89c113dc54485abe2692fc8e9ab30\"\n",
        "  tid = upload_file(token,audio_filepath)\n",
        "  result = {}\n",
        "  while result.get(\"status\") != 'processing':\n",
        "    result = get_text(token, tid)\n",
        "  while result.get(\"status\") != 'completed':\n",
        "    result = get_text(token, tid)\n",
        "  df = json_data_extraction(result,fname)\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zGTD6oWB-B8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Slicing "
      ],
      "metadata": {
        "id": "EaYXM26HpYy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OS1xElO-FDv",
        "outputId": "abfa5f87-ef88-4071-df54-de636a478f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os"
      ],
      "metadata": {
        "id": "BOxad8XB-HtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_audio_csv(audio_filepath,output_path):\n",
        "    # slicing/cropping audio files\n",
        "    audio_df =(generate_csv(audio_filepath))\n",
        "    fname = os.path.splitext(os.path.basename(audio_filepath))[0]\n",
        "    for i in range(len(audio_df)):\n",
        "        t1,t2 = audio_df.stime[i],audio_df.etime[i]\n",
        "        t1 = t1 * 1000\n",
        "        t2 = t2 * 1000\n",
        "        newAudio = AudioSegment.from_wav(audio_filepath)\n",
        "        newAudio = newAudio[t1:t2]\n",
        "        newAudio.export(output_path+str(t1)+'_'+str(t2)+'_'+fname+\".wav\", format=\"wav\")\n",
        "    print('Cropped Successfully.')\n",
        "    data = []\n",
        "    os.chdir(output_path)\n",
        "    output_path = os.getcwd()\n",
        "    for r, d, f in os.walk(output_path):\n",
        "       for file in f:\n",
        "            if \".wav\" in file:\n",
        "              data.append((os.path.join(r,file)))\n",
        "\n",
        "    df = pd.DataFrame(data,columns=['file'])\n",
        "    from natsort import natsort_keygen\n",
        "    df.sort_values(\n",
        "    by=\"file\",\n",
        "    key=natsort_keygen(),inplace=True)\n",
        "    df.reset_index(drop=True,inplace=True)\n",
        "    df= pd.concat([df,generate_csv(audio_filepath)['utter']], axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "buA4dotj-JU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir /content/crop_audio"
      ],
      "metadata": {
        "id": "2ThfgAne-MSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crop_audio_csv('/content/YouAngry.wav','/content/crop_audio/')"
      ],
      "metadata": {
        "id": "pUebJj0r-TLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SER Model"
      ],
      "metadata": {
        "id": "FH-d0ffBzqn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kFx4y3G_LIO",
        "outputId": "a90c7f70-7e61-4b7f-fa60-97f2ab1ee6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 91.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardx) (1.15.0)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import wave\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.backend_bases import RendererBase\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from scipy.fftpack import fft\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import chardet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.backend_bases import RendererBase\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "6fe423a8a12c49dcacb0167816426c0b",
            "d093a828f4614b34ad79a23dbcf7b511",
            "ce18b8ab685b48e78f5de1a6404cba60",
            "f623842d15654d8a8caf929711b21a82",
            "f131a1fdbdf34f61ad9e4d57ec626837",
            "ae1be03ae8e44e558f06efae0a6be784",
            "37ee6ecf4ad94c9bbbf9b73df54736b6",
            "778f8aa17d7c4e4eb1ca3b69dbefb6e0",
            "9b7a868118004b718910176fe0aab430",
            "66f931f7526b425087db12b40d5bd81f",
            "c86569759e1d4c46b5d1dc5d4dd2a548"
          ]
        },
        "id": "5nhZ5efQ_Lvi",
        "outputId": "d4b48579-fc2c-4ad2-fcd0-4b8b3f6314ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fe423a8a12c49dcacb0167816426c0b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Features "
      ],
      "metadata": {
        "id": "VekPEpx_zvs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audio2spectrogram(filepath):\n",
        "    #fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
        "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
        "    return spectrogram\n",
        "    \n",
        "def audio2wave(filepath):\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    plt.plot(test_sound)"
      ],
      "metadata": {
        "id": "AiIJvwn2_OQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_specgram(audio, sample_rate, window_size=40,\n",
        "                 step_size=20, eps=1e-10):\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "    freqs, _, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
      ],
      "metadata": {
        "id": "ITQu6YPX_TgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_CHANNELS = 3\n",
        "def get_3d_spec(Sxx_in, moments=None):\n",
        "    if moments is not None:\n",
        "        (base_mean, base_std, delta_mean, delta_std,\n",
        "             delta2_mean, delta2_std) = moments\n",
        "    else:\n",
        "        base_mean, delta_mean, delta2_mean = (0, 0, 0)\n",
        "        base_std, delta_std, delta2_std = (1, 1, 1)\n",
        "    h, w = Sxx_in.shape\n",
        "    right1 = np.concatenate([Sxx_in[:, 0].reshape((h, -1)), Sxx_in], axis=1)[:, :-1]\n",
        "    delta = (Sxx_in - right1)[:, 1:]\n",
        "    delta_pad = delta[:, 0].reshape((h, -1))\n",
        "    delta = np.concatenate([delta_pad, delta], axis=1)\n",
        "    right2 = np.concatenate([delta[:, 0].reshape((h, -1)), delta], axis=1)[:, :-1]\n",
        "    delta2 = (delta - right2)[:, 1:]\n",
        "    delta2_pad = delta2[:, 0].reshape((h, -1))\n",
        "    delta2 = np.concatenate([delta2_pad, delta2], axis=1)\n",
        "    base = (Sxx_in - base_mean) / base_std\n",
        "    delta = (delta - delta_mean) / delta_std\n",
        "    delta2 = (delta2 - delta2_mean) / delta2_std\n",
        "    stacked = [arr.reshape((h, w, 1)) for arr in (base, delta, delta2)]\n",
        "    return np.concatenate(stacked, axis=2)"
      ],
      "metadata": {
        "id": "6KPfu0hf_VpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet Model"
      ],
      "metadata": {
        "id": "XszVSFbYz4Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from .utils import load_state_dict_from_url\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((12, 12))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        print('features',x.shape)\n",
        "        return x\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "metadata": {
        "id": "qyM7NZSX_YOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified Alexnet "
      ],
      "metadata": {
        "id": "JsGCporiz8Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ModifiedAlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "        self.Sigmoid = nn.Sigmoid\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x=torch.flatten(x, start_dim=2)\n",
        "        x=torch.sum(x, dim=2)\n",
        "        x=self.classifier(x)\n",
        "        return x\n",
        "   \n",
        "def modifiedAlexNet(pretrained=False, progress=True, **kwargs):\n",
        "    model_modified = ModifiedAlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model_modified.load_state_dict(state_dict)\n",
        "    return model_modified"
      ],
      "metadata": {
        "id": "1YN6OPXo_Zf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        print('init of linear is done')\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None: \n",
        "            torch.nn.init.xavier_uniform_(m.bias)"
      ],
      "metadata": {
        "id": "50WfeAiy_b0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combined Audio Text Model"
      ],
      "metadata": {
        "id": "9kH5jeIC0AfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_text= []\n",
        "def hook_text(module, input, output):\n",
        "    outputs_text.clear()\n",
        "    outputs_text.append(output)\n",
        "    return None"
      ],
      "metadata": {
        "id": "mTf9p3IC_fEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_audio= []\n",
        "def hook_audio(module, input, output):\n",
        "    outputs_audio.clear()\n",
        "    outputs_audio.append(output)\n",
        "    return None"
      ],
      "metadata": {
        "id": "w2LFb5I7_g0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedAudioTextModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(CombinedAudioTextModel, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.text_model=torch.load('/content/drive/My Drive/model_text_best.pt')\n",
        "        self.audio_model=torch.load('/content/drive/MyDrive/model_audio_best.pt')\n",
        "\n",
        "        self.text_model.bert.pooler.register_forward_hook(hook_text)\n",
        "        self.audio_model.features.register_forward_hook(hook_audio)\n",
        "\n",
        "        for param in self.text_model.parameters():\n",
        "          param.requires_grad = False\n",
        "        for param in self.audio_model.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        self.dropout = nn.Dropout(.5)\n",
        "        self.linear = nn.Linear(1024, num_classes)\n",
        "\n",
        "        self.Sigmoid = nn.Sigmoid\n",
        "\n",
        "    def forward(self,text,audio):\n",
        "        self.text_model(text)\n",
        "        self.audio_model(audio)\n",
        "        audio_embed=outputs_audio[0]\n",
        "        text_embed=outputs_text[0]\n",
        "        audio_embed=torch.flatten(audio_embed, start_dim=2)#a1,a2,a3......al{a of dim c} \n",
        "        audio_embed=torch.sum(audio_embed, dim=2)\n",
        "        concat_embded=torch.cat((text_embed,audio_embed),1)\n",
        "        x=self.dropout(concat_embded)\n",
        "        x=self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HxWeMtos_i-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torch.load('/content/drive/MyDrive/Combined_model_audio_text.pt')\n",
        "model.eval()\n",
        "model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4B08U_C_jhv",
        "outputId": "296a729a-d8b8-40f1-b98a-c96d84f9652c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CombinedAudioTextModel(\n",
              "  (text_model): BertForSequenceClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              "  )\n",
              "  (audio_model): ModifiedAlexNet(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (9): ReLU(inplace=True)\n",
              "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (classifier): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=256, out_features=5, bias=True)\n",
              "    )\n",
              "    (softmax): Softmax(dim=1)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (linear): Linear(in_features=1024, out_features=5, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'ang': 0, 'hap': 1, 'neu': 3, 'sad': 2,'exc':4}\n",
        "indextolabel = dict()\n",
        "for key, value in label_dict.items():\n",
        "  indextolabel[value] = key"
      ],
      "metadata": {
        "id": "mflZ5gkw_lyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9b5b677c7d8747dd8cefc7d4d0710277",
            "1131c718470143bd88e01e3549edba29",
            "fe18b12e09354aec892449651c15bd43",
            "905ca4c55d16455aa7240a315f099af0",
            "32307ff7442c4ef796d89536b1cfe482",
            "83ee709b049c45e39bd07b02ea94a3e3",
            "37fd0c0a6b924a20aeb5cf9e802903c7",
            "2ca68784847446d3893587296ede223f",
            "3841d8f00445442c87bb35233391f75f",
            "f584d511b0e14e28a2f225967212b5ef",
            "40bc3f73fd7a49aa8d50673c807c87c9",
            "1036799f04a14c28ac243552ef8a4870",
            "ffff46519b514cc0bdeb6339cd02cc00",
            "46eccc3d5dc84be3a277bfdcf57a5057",
            "2a8c31197f0247d28432406aec07cbeb",
            "aa5ad979ceb247d692e5b9facd161963",
            "70172610177f49689f2583f16a589640",
            "0f34717e2c1748c193e67278f6480def",
            "097802d968944fdf97ff3027780f505d",
            "d122733e95034865a4cf0898de0b6e89",
            "d5978e323bb341f18aa0f7dba7036923",
            "f5ada72a7078411ba690f68c9b65ab71",
            "e6edfe08ce9c4d6498ec6cca84eb88eb",
            "37db39c78561409aa01d1cd175843879",
            "c7a64ef8b34b473b84b7e9e97529b7b7",
            "f06d7ed43bd1460dacb63cf862ae97fa",
            "f7dafeb84a0e4b12a4dbbdaa7b061455",
            "16fcebc15f3a4cc6b3cc6d3a46cc6be2",
            "0b83305c30fc461e97145690905d764b",
            "732a60eebace40c090591308c8a19087",
            "9fcc6963bffe474a855ea34068430cf7",
            "4df917701cee47d68a0de72a4138a96b",
            "3ade6fe43e7f4920bc9ea5303f89511b"
          ]
        },
        "id": "fbNW-b7H_ytv",
        "outputId": "766685d8-cb0e-46c8-832b-59a000d3b22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b5b677c7d8747dd8cefc7d4d0710277"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1036799f04a14c28ac243552ef8a4870"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6edfe08ce9c4d6498ec6cca84eb88eb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_audio(pathAudio):\n",
        "  #print(\"File to be converted {}\".format(pathAudio))\n",
        "  y, sr = librosa.load(pathAudio, sr = 16000, mono=True)\n",
        "  y = y * 32767 / max(0.01, np.max(np.abs(y)))\n",
        "  new_pathAudio = pathAudio.split(\".wav\")[0] + \"_converted.wav\"\n",
        "  #print(\"Converted file saved at {}\".format(new_pathAudio))\n",
        "  wavfile.write(new_pathAudio, sr, y.astype(np.int16))\n",
        "  return new_pathAudio"
      ],
      "metadata": {
        "id": "pzWsE5bf_zb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function For Predicting Emotion"
      ],
      "metadata": {
        "id": "JfnvtAI80gY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(file_path,text):\n",
        "  prob = None\n",
        "  preds = None\n",
        "  try:\n",
        "    if audio2spectrogram(file_path).shape[1] == 0: \n",
        "      return {}\n",
        "  except:\n",
        "     file_path = convert_audio(file_path)\n",
        "     filename=file_path.split('/')[-1].strip('.wav')\n",
        "     spector=audio2spectrogram(file_path)\n",
        "     spector=get_3d_spec(spector)\n",
        "     npimg = np.transpose(spector,(2,0,1))\n",
        "     input_tensor=torch.tensor(npimg)\n",
        "     sprectrome = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "     input_ids = torch.tensor(tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)\n",
        "     with torch.no_grad():\n",
        "        if (sprectrome.shape[2]>65):\n",
        "          output = model(input_ids,sprectrome)\n",
        "          m = nn.Softmax(dim=1)\n",
        "          probs = m(output)\n",
        "          preds = torch.argmax(probs)\n",
        "          prob = torch.max(probs)\n",
        "          #print(\"Predicted class is {} with {}% probability\".format(indextolabel[preds.item()], round(prob.item() * 100,2)))\n",
        "          #print()\n",
        "          probs = probs.tolist()[0]\n",
        "          emotion ={}\n",
        "          for i in range(len(probs)):\n",
        "            emotion[indextolabel[i]] = round(probs[i] * 100,2)         \n",
        "          return emotion"
      ],
      "metadata": {
        "id": "FzUq5XTt_11j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "xWkFzOJ1_4_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict Emotion (CSV File)"
      ],
      "metadata": {
        "id": "gi-wNbcy0nem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion_csv(audio_filepath,output_path):\n",
        "  df1 = crop_audio_csv(audio_filepath,output_path)\n",
        "  df1['emotions'] = df1.progress_apply(lambda x:predict_emotion((x['file']),x['utter']),axis=1 )\n",
        "  return df1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JIMnToCM_7K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict_emotion_csv('/content/combine.wav','/content/crop_audio/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Gh2_mo-QaQn",
        "outputId": "da4f864f-2c41-4b9c-9ffd-8cd0f37fbb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded File and got temporary URL to file\n",
            "Made request and file is currently queued\n",
            "Cropped Successfully.\n",
            "Uploaded File and got temporary URL to file\n",
            "Made request and file is currently queued\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/59 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 640 is greater than input length  = 2, using nperseg = 2\n",
            "  .format(nperseg, input_length))\n",
            "100%|██████████| 59/59 [00:11<00:00,  5.24it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               file  \\\n",
              "0            /content/crop_audio/0_9000_combine.wav   \n",
              "1        /content/crop_audio/9000_10000_combine.wav   \n",
              "2       /content/crop_audio/10000_10000_combine.wav   \n",
              "3       /content/crop_audio/11000_30000_combine.wav   \n",
              "4       /content/crop_audio/30000_49000_combine.wav   \n",
              "5       /content/crop_audio/49000_55000_combine.wav   \n",
              "6       /content/crop_audio/56000_77000_combine.wav   \n",
              "7       /content/crop_audio/77000_91000_combine.wav   \n",
              "8      /content/crop_audio/91000_117000_combine.wav   \n",
              "9     /content/crop_audio/117000_119000_combine.wav   \n",
              "10    /content/crop_audio/120000_120000_combine.wav   \n",
              "11    /content/crop_audio/121000_126000_combine.wav   \n",
              "12    /content/crop_audio/126000_145000_combine.wav   \n",
              "13    /content/crop_audio/145000_154000_combine.wav   \n",
              "14    /content/crop_audio/154000_154000_combine.wav   \n",
              "15    /content/crop_audio/154000_159000_combine.wav   \n",
              "16    /content/crop_audio/159000_189000_combine.wav   \n",
              "17    /content/crop_audio/190000_197000_combine.wav   \n",
              "18    /content/crop_audio/197000_226000_combine.wav   \n",
              "19    /content/crop_audio/226000_233000_combine.wav   \n",
              "20    /content/crop_audio/233000_272000_combine.wav   \n",
              "21    /content/crop_audio/272000_287000_combine.wav   \n",
              "22    /content/crop_audio/287000_288000_combine.wav   \n",
              "23    /content/crop_audio/289000_294000_combine.wav   \n",
              "24    /content/crop_audio/294000_296000_combine.wav   \n",
              "25    /content/crop_audio/296000_297000_combine.wav   \n",
              "26    /content/crop_audio/306000_335000_combine.wav   \n",
              "27    /content/crop_audio/335000_335000_combine.wav   \n",
              "28    /content/crop_audio/338000_387000_combine.wav   \n",
              "29    /content/crop_audio/394000_399000_combine.wav   \n",
              "30    /content/crop_audio/400000_402000_combine.wav   \n",
              "31    /content/crop_audio/402000_457000_combine.wav   \n",
              "32    /content/crop_audio/458000_560000_combine.wav   \n",
              "33    /content/crop_audio/560000_561000_combine.wav   \n",
              "34    /content/crop_audio/561000_562000_combine.wav   \n",
              "35    /content/crop_audio/562000_564000_combine.wav   \n",
              "36    /content/crop_audio/564000_578000_combine.wav   \n",
              "37    /content/crop_audio/579000_579000_combine.wav   \n",
              "38    /content/crop_audio/579000_590000_combine.wav   \n",
              "39    /content/crop_audio/602000_653000_combine.wav   \n",
              "40    /content/crop_audio/653000_728000_combine.wav   \n",
              "41    /content/crop_audio/730000_762000_combine.wav   \n",
              "42    /content/crop_audio/763000_854000_combine.wav   \n",
              "43    /content/crop_audio/855000_873000_combine.wav   \n",
              "44    /content/crop_audio/874000_877000_combine.wav   \n",
              "45    /content/crop_audio/878000_887000_combine.wav   \n",
              "46    /content/crop_audio/888000_890000_combine.wav   \n",
              "47    /content/crop_audio/890000_891000_combine.wav   \n",
              "48    /content/crop_audio/892000_893000_combine.wav   \n",
              "49    /content/crop_audio/893000_929000_combine.wav   \n",
              "50    /content/crop_audio/930000_931000_combine.wav   \n",
              "51    /content/crop_audio/931000_947000_combine.wav   \n",
              "52    /content/crop_audio/947000_948000_combine.wav   \n",
              "53   /content/crop_audio/950000_1018000_combine.wav   \n",
              "54  /content/crop_audio/1019000_1023000_combine.wav   \n",
              "55  /content/crop_audio/1023000_1071000_combine.wav   \n",
              "56  /content/crop_audio/1073000_1075000_combine.wav   \n",
              "57  /content/crop_audio/1075000_1098000_combine.wav   \n",
              "58  /content/crop_audio/1099000_1193000_combine.wav   \n",
              "\n",
              "                                                utter  \\\n",
              "0   Radix Web have, you know, amongst the best dev...   \n",
              "1                                                 Hi.   \n",
              "2   We've had a really positive experience working...   \n",
              "3   I think on both fronts, really good. I think f...   \n",
              "4   Look, it works pretty well. There's always goi...   \n",
              "5                                    Yes, absolutely.   \n",
              "6   I think the most impressive thing would be Rad...   \n",
              "7                                       That's right.   \n",
              "8   Yeah, look, I think the trust is built over ti...   \n",
              "9   The environment splendid. I think there's clea...   \n",
              "10  With look, I don't think there'd be one specif...   \n",
              "11                              Great. Happy to help.   \n",
              "12            We certainly have. Thank you very much.   \n",
              "13                                                Hi.   \n",
              "14  So there was a time when I was about to give u...   \n",
              "15  And I knew no one, but I also blended in there...   \n",
              "16                      It was an accidental suicide.   \n",
              "17  Oh, gosh. This one's very personal. But I was ...   \n",
              "18                                         Thank you.   \n",
              "19  Definitely my family and I did seek help. I we...   \n",
              "20  Yeah, she helped me a lot. And my little broth...   \n",
              "21  A little bit ago, my dog died. And I understoo...   \n",
              "22  So I used to battle with anorexia about two ye...   \n",
              "23  I thought about my family, friends, my dreams ...   \n",
              "24                                To move to America.   \n",
              "25  Yes. How did you pick one? I think there have ...   \n",
              "26  Thank you. It's a lot of feeling hopeless and ...   \n",
              "27  Antidepressants music, watching YouTube videos...   \n",
              "28  I really do, honestly. And I know this is like...   \n",
              "29  Oh, my goodness. I just want to hug him again ...   \n",
              "30  Welcome to the radius web. Today we are just g...   \n",
              "31  That's great. Thank you. What do you think abo...   \n",
              "32  You have been in this industry for quite a whi...   \n",
              "33   That's great. Since you're quite happy about it.   \n",
              "34  So tell me the most impressive thing about tha...   \n",
              "35  Steve yeah, I agree consistently of killing pe...   \n",
              "36  Why do you feel Reddixed is a trustable brand ...   \n",
              "37  Yes, of course. What do you think about this w...   \n",
              "38  Yes. One last one. Any specific reason you wou...   \n",
              "39  It sounds pretty exciting for us as well becau...   \n",
              "40  Thank you so much. Thank you very much for you...   \n",
              "41                                         Thank you.   \n",
              "42                                              Been.   \n",
              "43   8Th grade, I lost a really close friend of mine.   \n",
              "44  At that point I really didn't know how to cont...   \n",
              "45                        I'm glad you're still here.   \n",
              "46                    What helped you get through it?   \n",
              "47                           But you guys are sister?   \n",
              "48  So what made you change your mind and just kee...   \n",
              "49                              What are your dreams?   \n",
              "50                       Okay. So did that come true?   \n",
              "51                         I'm glad you haven't, too.   \n",
              "52                                        What helps?   \n",
              "53  So you literally think that those people askin...   \n",
              "54  If you could say something to Jason right now,...   \n",
              "55  So I'm trying to start a club at my high schoo...   \n",
              "56  Completely giving up probably yeah, not too lo...   \n",
              "57  Really. It's been within the last year with sc...   \n",
              "58  I was in high school. I had a really rough pro...   \n",
              "\n",
              "                                             emotions  \n",
              "0   {'ang': 2.61, 'hap': 42.21, 'sad': 0.15, 'neu'...  \n",
              "1                                                None  \n",
              "2                                                  {}  \n",
              "3   {'ang': 0.93, 'hap': 50.56, 'sad': 0.01, 'neu'...  \n",
              "4   {'ang': 4.43, 'hap': 22.85, 'sad': 0.28, 'neu'...  \n",
              "5   {'ang': 18.31, 'hap': 5.38, 'sad': 1.75, 'neu'...  \n",
              "6   {'ang': 0.04, 'hap': 90.11, 'sad': 0.01, 'neu'...  \n",
              "7   {'ang': 7.52, 'hap': 9.29, 'sad': 0.16, 'neu':...  \n",
              "8   {'ang': 4.83, 'hap': 28.18, 'sad': 0.04, 'neu'...  \n",
              "9   {'ang': 0.15, 'hap': 84.68, 'sad': 0.04, 'neu'...  \n",
              "10                                                 {}  \n",
              "11  {'ang': 0.09, 'hap': 90.82, 'sad': 0.02, 'neu'...  \n",
              "12  {'ang': 0.09, 'hap': 79.77, 'sad': 0.0, 'neu':...  \n",
              "13  {'ang': 6.16, 'hap': 10.63, 'sad': 0.23, 'neu'...  \n",
              "14                                                 {}  \n",
              "15  {'ang': 0.04, 'hap': 1.28, 'sad': 0.02, 'neu':...  \n",
              "16  {'ang': 0.2, 'hap': 56.03, 'sad': 4.0, 'neu': ...  \n",
              "17  {'ang': 4.19, 'hap': 33.96, 'sad': 43.83, 'neu...  \n",
              "18  {'ang': 1.97, 'hap': 9.17, 'sad': 0.27, 'neu':...  \n",
              "19  {'ang': 31.47, 'hap': 17.91, 'sad': 31.71, 'ne...  \n",
              "20  {'ang': 0.06, 'hap': 91.52, 'sad': 0.41, 'neu'...  \n",
              "21  {'ang': 17.68, 'hap': 15.42, 'sad': 32.27, 'ne...  \n",
              "22                                               None  \n",
              "23  {'ang': 10.33, 'hap': 7.31, 'sad': 68.43, 'neu...  \n",
              "24  {'ang': 5.61, 'hap': 36.19, 'sad': 1.25, 'neu'...  \n",
              "25                                               None  \n",
              "26  {'ang': 0.0, 'hap': 0.67, 'sad': 3.16, 'neu': ...  \n",
              "27                                                 {}  \n",
              "28  {'ang': 0.0, 'hap': 0.04, 'sad': 53.85, 'neu':...  \n",
              "29  {'ang': 0.24, 'hap': 9.44, 'sad': 82.6, 'neu':...  \n",
              "30  {'ang': 2.34, 'hap': 11.43, 'sad': 0.32, 'neu'...  \n",
              "31  {'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 99...  \n",
              "32  {'ang': 0.0, 'hap': 0.0, 'sad': 61.97, 'neu': ...  \n",
              "33                                               None  \n",
              "34                                               None  \n",
              "35  {'ang': 5.57, 'hap': 10.5, 'sad': 0.57, 'neu':...  \n",
              "36  {'ang': 0.0, 'hap': 0.02, 'sad': 0.03, 'neu': ...  \n",
              "37                                                 {}  \n",
              "38  {'ang': 0.0, 'hap': 0.07, 'sad': 0.25, 'neu': ...  \n",
              "39  {'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...  \n",
              "40  {'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...  \n",
              "41  {'ang': 0.0, 'hap': 0.68, 'sad': 7.47, 'neu': ...  \n",
              "42  {'ang': 0.0, 'hap': 0.0, 'sad': 0.29, 'neu': 9...  \n",
              "43  {'ang': 0.08, 'hap': 1.39, 'sad': 96.63, 'neu'...  \n",
              "44  {'ang': 4.02, 'hap': 9.85, 'sad': 75.95, 'neu'...  \n",
              "45  {'ang': 0.01, 'hap': 3.84, 'sad': 0.08, 'neu':...  \n",
              "46  {'ang': 5.13, 'hap': 11.95, 'sad': 1.91, 'neu'...  \n",
              "47                                               None  \n",
              "48                                               None  \n",
              "49  {'ang': 0.0, 'hap': 0.05, 'sad': 0.04, 'neu': ...  \n",
              "50                                               None  \n",
              "51  {'ang': 0.0, 'hap': 2.87, 'sad': 0.23, 'neu': ...  \n",
              "52                                               None  \n",
              "53  {'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...  \n",
              "54  {'ang': 1.27, 'hap': 0.88, 'sad': 85.14, 'neu'...  \n",
              "55  {'ang': 0.0, 'hap': 2.53, 'sad': 0.14, 'neu': ...  \n",
              "56  {'ang': 3.25, 'hap': 29.86, 'sad': 53.19, 'neu...  \n",
              "57  {'ang': 1.75, 'hap': 3.04, 'sad': 64.89, 'neu'...  \n",
              "58  {'ang': 0.0, 'hap': 0.0, 'sad': 100.0, 'neu': ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c9a1cb9-5a82-4b8a-8a43-1e6bca0af699\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>utter</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/crop_audio/0_9000_combine.wav</td>\n",
              "      <td>Radix Web have, you know, amongst the best dev...</td>\n",
              "      <td>{'ang': 2.61, 'hap': 42.21, 'sad': 0.15, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/crop_audio/9000_10000_combine.wav</td>\n",
              "      <td>Hi.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/crop_audio/10000_10000_combine.wav</td>\n",
              "      <td>We've had a really positive experience working...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/crop_audio/11000_30000_combine.wav</td>\n",
              "      <td>I think on both fronts, really good. I think f...</td>\n",
              "      <td>{'ang': 0.93, 'hap': 50.56, 'sad': 0.01, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/crop_audio/30000_49000_combine.wav</td>\n",
              "      <td>Look, it works pretty well. There's always goi...</td>\n",
              "      <td>{'ang': 4.43, 'hap': 22.85, 'sad': 0.28, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/crop_audio/49000_55000_combine.wav</td>\n",
              "      <td>Yes, absolutely.</td>\n",
              "      <td>{'ang': 18.31, 'hap': 5.38, 'sad': 1.75, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/crop_audio/56000_77000_combine.wav</td>\n",
              "      <td>I think the most impressive thing would be Rad...</td>\n",
              "      <td>{'ang': 0.04, 'hap': 90.11, 'sad': 0.01, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/crop_audio/77000_91000_combine.wav</td>\n",
              "      <td>That's right.</td>\n",
              "      <td>{'ang': 7.52, 'hap': 9.29, 'sad': 0.16, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/crop_audio/91000_117000_combine.wav</td>\n",
              "      <td>Yeah, look, I think the trust is built over ti...</td>\n",
              "      <td>{'ang': 4.83, 'hap': 28.18, 'sad': 0.04, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/crop_audio/117000_119000_combine.wav</td>\n",
              "      <td>The environment splendid. I think there's clea...</td>\n",
              "      <td>{'ang': 0.15, 'hap': 84.68, 'sad': 0.04, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/crop_audio/120000_120000_combine.wav</td>\n",
              "      <td>With look, I don't think there'd be one specif...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/crop_audio/121000_126000_combine.wav</td>\n",
              "      <td>Great. Happy to help.</td>\n",
              "      <td>{'ang': 0.09, 'hap': 90.82, 'sad': 0.02, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/crop_audio/126000_145000_combine.wav</td>\n",
              "      <td>We certainly have. Thank you very much.</td>\n",
              "      <td>{'ang': 0.09, 'hap': 79.77, 'sad': 0.0, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/crop_audio/145000_154000_combine.wav</td>\n",
              "      <td>Hi.</td>\n",
              "      <td>{'ang': 6.16, 'hap': 10.63, 'sad': 0.23, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/crop_audio/154000_154000_combine.wav</td>\n",
              "      <td>So there was a time when I was about to give u...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/crop_audio/154000_159000_combine.wav</td>\n",
              "      <td>And I knew no one, but I also blended in there...</td>\n",
              "      <td>{'ang': 0.04, 'hap': 1.28, 'sad': 0.02, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/crop_audio/159000_189000_combine.wav</td>\n",
              "      <td>It was an accidental suicide.</td>\n",
              "      <td>{'ang': 0.2, 'hap': 56.03, 'sad': 4.0, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/crop_audio/190000_197000_combine.wav</td>\n",
              "      <td>Oh, gosh. This one's very personal. But I was ...</td>\n",
              "      <td>{'ang': 4.19, 'hap': 33.96, 'sad': 43.83, 'neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/crop_audio/197000_226000_combine.wav</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>{'ang': 1.97, 'hap': 9.17, 'sad': 0.27, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/crop_audio/226000_233000_combine.wav</td>\n",
              "      <td>Definitely my family and I did seek help. I we...</td>\n",
              "      <td>{'ang': 31.47, 'hap': 17.91, 'sad': 31.71, 'ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/content/crop_audio/233000_272000_combine.wav</td>\n",
              "      <td>Yeah, she helped me a lot. And my little broth...</td>\n",
              "      <td>{'ang': 0.06, 'hap': 91.52, 'sad': 0.41, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>/content/crop_audio/272000_287000_combine.wav</td>\n",
              "      <td>A little bit ago, my dog died. And I understoo...</td>\n",
              "      <td>{'ang': 17.68, 'hap': 15.42, 'sad': 32.27, 'ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/content/crop_audio/287000_288000_combine.wav</td>\n",
              "      <td>So I used to battle with anorexia about two ye...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/content/crop_audio/289000_294000_combine.wav</td>\n",
              "      <td>I thought about my family, friends, my dreams ...</td>\n",
              "      <td>{'ang': 10.33, 'hap': 7.31, 'sad': 68.43, 'neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/content/crop_audio/294000_296000_combine.wav</td>\n",
              "      <td>To move to America.</td>\n",
              "      <td>{'ang': 5.61, 'hap': 36.19, 'sad': 1.25, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/content/crop_audio/296000_297000_combine.wav</td>\n",
              "      <td>Yes. How did you pick one? I think there have ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/content/crop_audio/306000_335000_combine.wav</td>\n",
              "      <td>Thank you. It's a lot of feeling hopeless and ...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.67, 'sad': 3.16, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/content/crop_audio/335000_335000_combine.wav</td>\n",
              "      <td>Antidepressants music, watching YouTube videos...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/content/crop_audio/338000_387000_combine.wav</td>\n",
              "      <td>I really do, honestly. And I know this is like...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.04, 'sad': 53.85, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/content/crop_audio/394000_399000_combine.wav</td>\n",
              "      <td>Oh, my goodness. I just want to hug him again ...</td>\n",
              "      <td>{'ang': 0.24, 'hap': 9.44, 'sad': 82.6, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>/content/crop_audio/400000_402000_combine.wav</td>\n",
              "      <td>Welcome to the radius web. Today we are just g...</td>\n",
              "      <td>{'ang': 2.34, 'hap': 11.43, 'sad': 0.32, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>/content/crop_audio/402000_457000_combine.wav</td>\n",
              "      <td>That's great. Thank you. What do you think abo...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 99...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>/content/crop_audio/458000_560000_combine.wav</td>\n",
              "      <td>You have been in this industry for quite a whi...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 61.97, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>/content/crop_audio/560000_561000_combine.wav</td>\n",
              "      <td>That's great. Since you're quite happy about it.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>/content/crop_audio/561000_562000_combine.wav</td>\n",
              "      <td>So tell me the most impressive thing about tha...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>/content/crop_audio/562000_564000_combine.wav</td>\n",
              "      <td>Steve yeah, I agree consistently of killing pe...</td>\n",
              "      <td>{'ang': 5.57, 'hap': 10.5, 'sad': 0.57, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>/content/crop_audio/564000_578000_combine.wav</td>\n",
              "      <td>Why do you feel Reddixed is a trustable brand ...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.02, 'sad': 0.03, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>/content/crop_audio/579000_579000_combine.wav</td>\n",
              "      <td>Yes, of course. What do you think about this w...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>/content/crop_audio/579000_590000_combine.wav</td>\n",
              "      <td>Yes. One last one. Any specific reason you wou...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.07, 'sad': 0.25, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>/content/crop_audio/602000_653000_combine.wav</td>\n",
              "      <td>It sounds pretty exciting for us as well becau...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>/content/crop_audio/653000_728000_combine.wav</td>\n",
              "      <td>Thank you so much. Thank you very much for you...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>/content/crop_audio/730000_762000_combine.wav</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.68, 'sad': 7.47, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>/content/crop_audio/763000_854000_combine.wav</td>\n",
              "      <td>Been.</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 0.29, 'neu': 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>/content/crop_audio/855000_873000_combine.wav</td>\n",
              "      <td>8Th grade, I lost a really close friend of mine.</td>\n",
              "      <td>{'ang': 0.08, 'hap': 1.39, 'sad': 96.63, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>/content/crop_audio/874000_877000_combine.wav</td>\n",
              "      <td>At that point I really didn't know how to cont...</td>\n",
              "      <td>{'ang': 4.02, 'hap': 9.85, 'sad': 75.95, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>/content/crop_audio/878000_887000_combine.wav</td>\n",
              "      <td>I'm glad you're still here.</td>\n",
              "      <td>{'ang': 0.01, 'hap': 3.84, 'sad': 0.08, 'neu':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>/content/crop_audio/888000_890000_combine.wav</td>\n",
              "      <td>What helped you get through it?</td>\n",
              "      <td>{'ang': 5.13, 'hap': 11.95, 'sad': 1.91, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>/content/crop_audio/890000_891000_combine.wav</td>\n",
              "      <td>But you guys are sister?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>/content/crop_audio/892000_893000_combine.wav</td>\n",
              "      <td>So what made you change your mind and just kee...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>/content/crop_audio/893000_929000_combine.wav</td>\n",
              "      <td>What are your dreams?</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.05, 'sad': 0.04, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>/content/crop_audio/930000_931000_combine.wav</td>\n",
              "      <td>Okay. So did that come true?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>/content/crop_audio/931000_947000_combine.wav</td>\n",
              "      <td>I'm glad you haven't, too.</td>\n",
              "      <td>{'ang': 0.0, 'hap': 2.87, 'sad': 0.23, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>/content/crop_audio/947000_948000_combine.wav</td>\n",
              "      <td>What helps?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>/content/crop_audio/950000_1018000_combine.wav</td>\n",
              "      <td>So you literally think that those people askin...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 0.0, 'neu': 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>/content/crop_audio/1019000_1023000_combine.wav</td>\n",
              "      <td>If you could say something to Jason right now,...</td>\n",
              "      <td>{'ang': 1.27, 'hap': 0.88, 'sad': 85.14, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>/content/crop_audio/1023000_1071000_combine.wav</td>\n",
              "      <td>So I'm trying to start a club at my high schoo...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 2.53, 'sad': 0.14, 'neu': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>/content/crop_audio/1073000_1075000_combine.wav</td>\n",
              "      <td>Completely giving up probably yeah, not too lo...</td>\n",
              "      <td>{'ang': 3.25, 'hap': 29.86, 'sad': 53.19, 'neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>/content/crop_audio/1075000_1098000_combine.wav</td>\n",
              "      <td>Really. It's been within the last year with sc...</td>\n",
              "      <td>{'ang': 1.75, 'hap': 3.04, 'sad': 64.89, 'neu'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>/content/crop_audio/1099000_1193000_combine.wav</td>\n",
              "      <td>I was in high school. I had a really rough pro...</td>\n",
              "      <td>{'ang': 0.0, 'hap': 0.0, 'sad': 100.0, 'neu': ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c9a1cb9-5a82-4b8a-8a43-1e6bca0af699')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c9a1cb9-5a82-4b8a-8a43-1e6bca0af699 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c9a1cb9-5a82-4b8a-8a43-1e6bca0af699');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}